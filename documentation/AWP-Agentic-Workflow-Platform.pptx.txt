AWP Agentic Workflow Platform
Architecture Study
Mohamad NABAA
20 Janvier 2026
Bonjour à tout et à tous ! 
Je m'appelle Mohamad Nabaa. 
J'ai 15 ans d'expérience dans le domaine technologique, dont 8 ans comme architecte de solutions et 4 ans dans le domaine de l'IA générique. 
Dans le cadre de ce processus de recrutement, vous m'avez demandé de préparer une présentation architecturale pour un client du secteur du luxe.
La présentation couvrira :

1

Sommaire
Index
01
Introduction
02
Logical Architecture
03
Physical Architecture
04
RAG Strategies
05
Advantages
06
TCO & Roadmap
07
Conclusion
2

Vision
Transform from Static Chatbot to Sovereign Agentic Platform
Use Case
LUXE Sector client with 25000 internal users, are using a static chatbot that provides information but lack the capability to perform autonomous operational actions.
Introduction 
Objective
Create a Sovereign Agentic-powered "Virtual Team" that executes complex tasks while keeping the human in the loop for actions.
Cas d’usage : Un client du secteur du luxe a 25 000 utilisateurs internes qui utilisent un chatbot statique sur leur intranet.
Un client du secteur du luxe compte 25 000 utilisateurs internes qui utilisent un chatbot statique sur leur intranet.
L'objectif est de développer une plateforme agentique pour renforcer les compétences de vos collaborateurs.


Logical Architecture
Logical Architecture (The "Virtual Team")
Stateful Multi-Agent Orchestration with End-to-End Observability
Pour cette plateforme agentique :
Nous avons choisi le modèle Superviseur/Agent pour garantir une gouvernance centralisée.
 Un superviseur (LangGraph) orchestre des agents spécialisés (CrewAI) 
capables d'exécuter des actions complexes via leurs outils connectés.
Chaque décision prise par l'IA est tracée et remontée par Langfuse vers Cloud Logging pour garantir une transparence et une observabilité totales.

4

Physical Architecture
Physical Architecture
Zero-Trust Serverless Enclave for Enterprise GenAI (europe-west-9)
Pour l’architecture physique souveraine et Zero-Trust :
Nous avons choisi un design serverless pour notre orchestrateur avec Confidential GKE Autopilot (incluant le chiffrement de lamémoire au niveau matériel (AMD SEV-SNP).
Côté réseau, nous intégrons :
VPC Service Control (région europe-west-9).
Une Sovereign Access Gate avec IAP Auth + Access Approval.
Cloud NAT pour la gestion de l'EGRESS.


================================================================================================================================================================================Zero-Trust Hardware-Enforced Enclave (europe-west-9)
Infrastructure Breakdown:
Orchestrator (The Brain): Confidential GKE Autopilot running LangGraph. Hardware-level memory encryption (AMD SEV-SNP) ensures the supervisor's reasoning logic is invisible to the provider.
Vertex AI Endpoints. BUT can change to Models deployed on N2D/C3 machine types with the "Confidential Computing" toggle enabled to eliminate the "RAM Gap" during processing
Sovereign Access Gate: IAP Auth + Access Approval. Dual-layer security requiring explicit user identity verification and time-bound client approval before any administrative provider access.
Networking: VPC Service Control (europe-west-9) perimeter encompassing all components to prevent data exfiltration to unauthorized external IPs.

5

Architecture
Architecture
Asynchronous Python native stack
Here's a breakdown of our technical architecture:
Stack
LangGraph for graph orchestration, LangChain for native tools
CrewAI for agent implementation
FastAPI for the async server runtime
FastMCP for MCP server/client services
Terraform: Infrastructure as Code
Observability
Langfuse Monitoring traces every graph node state transition, exports logs to Cloud Logging and Grafana or (Cloud Trace) for production monitoring.
Governance
Sensitive Data Protection sidecar: (GCP managed service) for PII redaction at ingress and industry standard guard rails

Interrupt-based approval flow for high-risk or agent flagged actions (Human-in-Loop validated via IAP identity).
Model Armor: Intent Validation, blocking malicious "jailbreak" commands or prompt injections before they reach the LLM orchestrator.
6

RAG Strategies
Multi-Modal Agentic RAG
Autonomous Multi-Source Intelligence: Orchestrating Hybrid Retrieval with Self-Correcting Logic and Enterprise-Grade Governance
Pattern A: Adaptive Semantic Search
(Unstructured) 
Vector Engine: Vertex AI RAG Engine using text-embedding-005 for high-dimensional accuracy.

Chunking Strategy: Layout-Aware & Semantic Chunking to preserve document hierarchy.

Reranking: Cross-Encoder Rerankernode to score the most relevant 3-5 passages, reducing "lost in the middle" hallucinations.

Pattern B: Verified Analytical Query (Structured)
Engine: LangChain Semantic Text-to-SQL feeding into BigQuery.


Governance: Mandatory Dry Run Validation via a Read-Only Service Account to ensure zero data-leakage.

Few-Shot examples: Uses a vector store of "Golden Query-SQL" pairs to guide the agent in generating high-accuracy queries for complex luxury inventory metrics.

Pattern C: Hybrid Agentic Orchestrator (Cross-Source)
Logic: LangGraph Supervisor decomposes complex multi-source requests (e.g., "Compare sales trends against last month's policy update").

Self-Correction Loop: If the initial retrieval is irrelevant, a Query Transformation node automatically rewrites the prompt and triggers a second search attempt.

Le Mémoire Externe de notre client a:Unstructured Data: Confluence+Drive + RAG Ephemeral
Structured Data: BigQuery
7

Comparative Analysis
Advantages
Advantage
Agentic Platform Capability
Operational Efficiency
Agents offload L1/L2 support and operational cost
Reduced MTTR
Automated workflows vs manual processes
Control
100% EU Data Residency with Zero-Trust security in a serverless enclave.
Full ownership of the "AI Brain," specialized logic, and system connectors.
Sovereignty
Scalability
Horizontal, demand-driven scaling with usage-dependent serverless costing.
Économies : Réduction drastique des frais de support (L1/L2).
Vitesse : Automatisation des workflows vs processus manuels.
Contrôle : Souveraineté UE vs Opacité des modèles standards.
Flexibilité : Paiement à l'usage (Serverless) vs Coûts fixes.

8

Planification
TCO & Roadmap
Build Phase
CapEx: Estimated Cost: €480K->€660K
3-6 months, Requires 6-7 FTE Squad:
1 Cloud Architect
2 Senior AI Engineer
1 Data Engineer
1 DevSecOps / Security Architect
Run Phase
OpEx: Infrastructure €8,000 - €10,000 / month in pilot phase
GCP Infrastructure + LLM Tokens for ~1k users
Operational Team
Requires 2.5 FTE -> (Platform Engineer + FinOps/Security Analyst ) + 0.5 FTE to maintain connectors and governance
1 UX/Product Lead
1 Frontend Dev
9

Conclusion
Agentic Workflow Platform
Total replacement of a static chatbot. 
Activates autonomous agents with a human in the loop while preserving observability and governance. Scalable on demand and secure.
Budget
Cost Offset
Development budget replaces recurring 1 year for most of L1/L2 support cost.
Value
Ownership
We own the "Brain" and the "Connectors" (no Black Box SaaS).
En résumé : ont remplace un coût récurrent par un actif stratégique sécurisé, souverain et performant
10

Merci
Q/A

Annex


Phase
Timeline
Key Activities
Technical Focus
Foundation
Month 1-2
Setup VPC Service Controls & Confidential GKE Cluster.
Security: Establishing the Zero-Trust serverless enclave in europe-west-9
Logic & Agents
Month 2-3
Develop the LangGraph Supervisor and specialized CrewAI agents (IT, Ops, Analyst).
Orchestration: Implementing stateful multi-agent flows with FastAPI and LangGraph.

Resilience (Queue)
Month 3-4
Implement Cloud Tasks for long-running (3–5 min) actions and Transient RAG processing.

Connects the Confidential GKE orchestrator to asynchronous background services for higher reliability
End-User HITL
Month 4-5
Integrating the "Interrupt" UI to facilitate Human-in-the-Loop (HITL) approvals for high-risk actions.
Governance: Using IAP identity to validate high-risk actions before execution
Run Phase
Month 6+
Production rollout to 25k users with 100% EU residency.
Scalability: Managed by horizontal, demand-driven serverless scaling via Confidential GKE Autopilot.

Zero Trust
